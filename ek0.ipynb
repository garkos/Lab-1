{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy\n",
    "\n",
    "# Function to open a file dialog and select a CSV file\n",
    "def load_file():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Close the root window\n",
    "    file_path = filedialog.askopenfilename(title=\"Select file\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    return file_path\n",
    "\n",
    "# 1. Load data, print column names and dataset size\n",
    "file_path = load_file()\n",
    "if file_path:  # Ensure a file was selected\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Column names:\", df.columns)\n",
    "    print(\"Dataset size:\", df.shape)\n",
    "else:\n",
    "    print(\"No file selected. Exiting the script.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Handle missing values (fill or drop if possible)\n",
    "print(df.isnull().sum())  # Check the number of missing values in each column\n",
    "\n",
    "# Fill missing values only in numerical columns\n",
    "df.fillna(df.select_dtypes(include=['float64', 'int64']).mean(), inplace=True)\n",
    "\n",
    "# 3. Data visualization: correlation heatmap and histograms\n",
    "# Select only numerical columns for correlation matrix\n",
    "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = numerical_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Histograms of feature distributions\n",
    "df.hist(bins=30, figsize=(12, 10))\n",
    "plt.suptitle(\"Feature Distribution Histograms\")\n",
    "plt.show()\n",
    "\n",
    "# Automatically detect target and features based on the dataset\n",
    "\n",
    "# Detect target variable (categorical column with few unique values)\n",
    "def detect_target(df, max_unique_values=10):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object' or df[column].nunique() <= max_unique_values:\n",
    "            return column\n",
    "    return None\n",
    "\n",
    "# Detect features (numerical columns)\n",
    "def detect_features(df, exclude_column):\n",
    "    features = []\n",
    "    for column in df.columns:\n",
    "        if column != exclude_column and df[column].dtype in ['float64', 'int64']:\n",
    "            features.append(column)\n",
    "    return features\n",
    "\n",
    "# Detect target and features from the dataset\n",
    "target = detect_target(df)\n",
    "features = detect_features(df, target)\n",
    "\n",
    "if target is not None and len(features) > 0:\n",
    "    print(f\"Detected target: {target}\")\n",
    "    print(f\"Detected features: {features}\")\n",
    "else:\n",
    "    print(\"Failed to detect target or features.\")\n",
    "\n",
    "# Proceed with the rest of the code using detected target and features\n",
    "# Boxplots of features relative to the target variable\n",
    "for feature in features:\n",
    "    if feature in df.columns:\n",
    "        sns.boxplot(x=target, y=feature, data=df)\n",
    "        plt.title(f\"Boxplot of {feature} vs {target}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Feature {feature} not found in dataframe columns\")\n",
    "\n",
    "# Boxplots of features relative to the target variable\n",
    "for feature in features:\n",
    "    if feature in df.columns:\n",
    "        sns.boxplot(x=target, y=feature, data=df)\n",
    "        plt.title(f\"Boxplot of {feature} vs {target}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Feature {feature} not found in dataframe columns\")\n",
    "\n",
    "# 4. Normalize data\n",
    "# Ensure only numerical columns are included for normalization\n",
    "features_df = df[features]\n",
    "\n",
    "# Drop columns with non-numeric data before normalization\n",
    "numerical_features_df = features_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numerical_features_df)  # Normalize features\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=numerical_features_df.columns)  # Create a new DataFrame\n",
    "\n",
    "# 5. Train classifiers\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, df[target], test_size=0.3, random_state=42)\n",
    "\n",
    "# kNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNN:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(\"Decision Tree:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "# SVM with GridSearchCV for parameter tuning\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]}\n",
    "grid_svm = GridSearchCV(SVC(), param_grid_svm, refit=True, verbose=2)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "print(\"SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# AdaBoost\n",
    "ada = AdaBoostClassifier(algorithm='SAMME')\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "print(\"AdaBoost:\")\n",
    "print(classification_report(y_test, y_pred_ada, labels=numpy.unique(y_pred_ada)))\n",
    "print(confusion_matrix(y_test, y_pred_ada))\n",
    "\n",
    "# Parameter tuning for kNN\n",
    "param_grid_knn = {'n_neighbors': list(range(1, 31))}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, refit=True)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "print(\"Optimal n_neighbors for kNN:\", grid_knn.best_params_)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
